# -*- coding: utf-8 -*-
"""2nd_assignment_ShoppingAgent.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dmemVMMEWn5R09NWSkF0QOWIbT8vx3EA
"""

# Step 1:Install required libraries
!pip install -U langchain-google-genai langchain requests #-U used for upgrade latest compatible versions
#langchain for langchain libraries and google-genai for gemini models
#i used a fakestore website so to call that..  requests used

# Step 2: Import modules

import os                           # For environment variables like the API key
import requests                     # For making HTTP requests to FakeStoreAPI

# for initializing agents
from langchain.agents import initialize_agent, AgentType

# Tool is the LangChain wrapper that exposes a Python function to the agent
from langchain.tools import Tool

# ChatGoogleGenerativeAI is the LangChain LLM wrapper for Gemini
from langchain_google_genai import ChatGoogleGenerativeAI

# Step 3: Set up Gemini API key

# Using getpass keeps key hidden in the notebook UI.
from getpass import getpass

#key entering msg
GOOGLE_API_KEY = getpass(" Enter your Google (Gemini) API key: ")

# Store it in an environment variable so the LangChain wrapper can read it
os.environ["GOOGLE_API_KEY"] =GOOGLE_API_KEY

# Step 4: Define a tool to fetch products from FakeStoreAPI


def fetch_products(query: str) -> str:
    """
    Fetch products from FakeStoreAPI and filter by keyword in title or category.
    """
    try:
        data = requests.get("https://fakestoreapi.com/products", timeout=10).json() #calls fakestore and product data
    except Exception as e:
        return f" Could not reach FakeStoreAPI: {e}" #if calling fails,then this msg shown up

    query_lower = query.lower() #making it into lower cases for better matching

    # Collect matches (title or category contains query)
    results = [
        f"{p['title']} — ${p['price']}"
        for p in data
        if query_lower in p["title"].lower() or query_lower in p["category"].lower()
    ]

    return "Here are some matches:\n" + "\n".join(results[:5]) if results else "No products found for your query."

# Step 5: Wrap the function as a LangChain Tool

tool = Tool(
    name="ProductSearchAPI",                    # it's a tool that agent uses
    func=fetch_products,                        # Python function the agent will call
    description=(
        "Searches products from FakeStoreAPI. "
        "Give it a keyword like 'shirt', 'electronics', or 'jewelery' "
        "and it will return matching titles with prices."
   ),
)

# Step 6: Initialize Gemini LLM

# Create the Gemini chat model wrapper.
llm = ChatGoogleGenerativeAI(
    model="gemini-1.5-flash",  # used gemini 1.5 flash cause its fast amd cheaper
    temperature=0.3            # temp near to 0 so it is more focused/less random
)

# Step 7: Initialize the Agent

# Build an agent that:
#  - reads the user's query,
#  - decides whether to call ProductSearchAPI,
#  - and then returns a helpful answer.
agent = initialize_agent(
    tools=[tool],                                   # The list of tools the agent can use
    llm=llm,                                        # The Gemini model defined above
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,    # Classic ReAct-style tool-using agent - Reason+act
    verbose=True,                                   # Prints the reasoning steps in Colab output
    handle_parsing_errors=True                      # Makes the agent more forgiving if it stumbles
)

# Step 8: Run the bot

print("----  E-commerce Recommendation Bot ----")

# Ask the user what they want
user_query = input("What are you looking for? ")

# Run the agent with .invoke()
result = agent.invoke({"input": user_query})

# Extract the final output text
response = result["output"]

# Show the result
print("\n Bot Recommendation:\n",response)